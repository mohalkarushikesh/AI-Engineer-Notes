### ðŸ§  **Support Vector Machine (SVM) â€“ Quick Notes**

**1. What is SVM?**  
SVM is a supervised machine learning algorithm used mainly for **classification**, but it can also be used for regression.

**2. Basic Idea:**  
It finds the **best boundary (hyperplane)** that separates classes with the **maximum margin** â€” the greatest distance between data points of both classes.

**3. Key Terms:**
- **Hyperplane**: A line (in 2D), plane (in 3D), or n-dimensional boundary that separates classes.
- **Support Vectors**: Data points closest to the hyperplane; they define the margin and are critical to the model.
- **Margin**: The distance between the hyperplane and the closest support vectors from each class.

**4. Linear vs. Nonlinear SVM:**
- **Linear SVM**: Works well when data is linearly separable.
- **Nonlinear SVM**: Uses **kernel tricks** (like RBF or polynomial) to map data into higher dimensions for separation when data isnâ€™t linearly separable.

**5. Kernels:**  
Kernels help transform data into a higher dimension:
- **Linear Kernel**
- **Polynomial Kernel**
- **Radial Basis Function (RBF) Kernel**
- **Sigmoid Kernel**

**6. Advantages:**
- Works well with high-dimensional data.
- Effective in cases where the number of features > number of samples.
- Robust to overfitting, especially with a proper kernel.

**7. Disadvantages:**
- Not ideal for very large datasets (can be slow).
- Doesnâ€™t perform well when thereâ€™s significant noise or overlapping classes.
- Choosing the right kernel and parameters (like C and gamma) can be tricky.
