**Differentials**: optimize by finding minima and maxima of curves 
  - uses in engg (max strength ) and finance (min cost)
  - widely used in ML and DL
  - gradient descent to minimize the cost
  - gradient descent to maximize reward
  - Higher order derivates used in fancy optimizers (optimization)

**Integrals**: Find area under the curve
  - Receiver operating charateristics (cal II)
  - probablity theory expectation of random variable is widely used in ML incl. DL

**Calculating limits**: 
    
