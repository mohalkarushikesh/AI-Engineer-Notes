Journey of AI
  2017: Attention is all you need 
  2018: GPT 1
  2019: GPT 2
  2020: GPT 3
  2022: RLHF AND CHATGPT 
  2023: GPT 4
  2024: GPT 4O

predictive text on steroids, the stochastic parrot : ex keyboard predicting the next word 

Intraducing tokens 
Charater level => off words => chunks of words called 'tokens'

GPT Tokenizer view: fhttps://platform.openai.com/tokenizer

1 token ~ 4 charaters
1 token ~ 0.75 words
so 1000 tokens is ~750 words

context window: max no of tokens that the model can consider when generating the next token particularly imp for multi shot 

API cost : based on no of input tokens and no of output tokens 

vellum (LLM leatherboard)

day 5 : project: Bussiness Challenge (check it very important)





